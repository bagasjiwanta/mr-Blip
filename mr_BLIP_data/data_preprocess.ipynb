{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4204c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/determined/pythonuserbase/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "import random\n",
    "# from tqdm import tqdm\n",
    "# tqdm for notebooks\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e807f09",
   "metadata": {},
   "source": [
    "# create folder for each dataset first    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09845339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(content, save_path):\n",
    "    # if no such directory, create one\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(json.dumps(content))\n",
    "def load_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [json.loads(l.strip(\"\\n\")) for l in f.readlines()]\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7083bf5",
   "metadata": {},
   "source": [
    "# qvh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = 'Your/path/to/QVHighlights'\n",
    "train_path = ann_root + '/highlight_train_release.jsonl'\n",
    "val_path = ann_root + '/highlight_val_release.jsonl'\n",
    "test_path = ann_root + '/highlight_test_release.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)\n",
    "test = load_jsonl(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d681ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_QVH(data, relative_time=False, save_float=False, is_test=False):\n",
    "    out = []\n",
    "    for d in data:\n",
    "        sample = {}\n",
    "        sample['video'] = d['vid']\n",
    "        sample['qid'] = 'QVHighlight_' + str(d['qid'])\n",
    "        sample['query'] = d['query']\n",
    "        duration = d['duration']\n",
    "        sample['duration'] = duration\n",
    "\n",
    "        if not is_test:\n",
    "            windows = d['relevant_windows']\n",
    "            if relative_time:\n",
    "                relative_time_windows = []\n",
    "                for window in windows:\n",
    "                    start = window[0] / duration\n",
    "                    end = window[1] / duration\n",
    "\n",
    "                    if save_float:\n",
    "                        relative_time_windows.append([round(start, 2), round(end, 2)])\n",
    "                    else:\n",
    "                        relative_time_windows.append([int(round(start, 2) * 100), int(round(end, 2) * 100)])\n",
    "                sample['relevant_windows'] = relative_time_windows\n",
    "            else:\n",
    "                sample['relevant_windows'] = windows\n",
    "        else:\n",
    "            sample['relevant_windows'] = [[0, 150]] # dummy value\n",
    "\n",
    "        out.append(sample)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507365fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "new_train = process_QVH(train, relative_time=relative_time, save_float=save_float)\n",
    "new_val = process_QVH(val, relative_time=relative_time, save_float=save_float)\n",
    "new_test = process_QVH(test, relative_time=relative_time, save_float=save_float, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9754fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float_dummy.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float_dummy.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_dummy.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_dummy.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151075f",
   "metadata": {},
   "source": [
    "# Charades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Your/path/to/Charades_v1_train.csv', delimiter=',')\n",
    "test_df = pd.read_csv('Your/path/to/Charades_v1_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique ids\n",
    "train_ids = train_df[\"id\"].unique()\n",
    "print(len(train_ids))\n",
    "\n",
    "# randomly select 800 ids for validation\n",
    "random.seed(42)\n",
    "random.shuffle(train_ids)\n",
    "\n",
    "val_ids = train_ids[:800]\n",
    "train_ids = train_ids[800:]\n",
    "\n",
    "len(val_ids), len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = 'Your/path/to/Charades_STA'\n",
    "train_path = ann_root + '/train.txt'\n",
    "test_path = ann_root + '/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_charades_STA(data_path, df, video_ids=None, relative_time=False, save_float=False):\n",
    "    # read txt and put each line into new element in list\n",
    "    with open(data_path) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    out = []\n",
    "\n",
    "    for s in content:\n",
    "        # format \"id start end##query\"\n",
    "        s = s.split('##') # -> [id start end, query]\n",
    "        query = s[1] # -> query\n",
    "        s = s[0] # -> id start end\n",
    "        s = s.split(' ') # -> [[id], [start], [end]]\n",
    "        id = s[0] # -> id\n",
    "\n",
    "        if video_ids is not None and id not in video_ids:\n",
    "            continue\n",
    "        \n",
    "        # get meta data from df using id\n",
    "        # get row with id == id\n",
    "        row = df.loc[df[\"id\"] == id]\n",
    "        values = row.values[0]\n",
    "\n",
    "        # get duration\n",
    "        duration = values[10]\n",
    "\n",
    "        # convert to float\n",
    "        s[1] = float(s[1])\n",
    "        s[2] = float(s[2])\n",
    "        if s[2] > duration:\n",
    "            s[2] = duration\n",
    "\n",
    "        if relative_time:\n",
    "            # convert to relative time\n",
    "            s[1] = s[1] / duration\n",
    "            s[2] = s[2] / duration\n",
    "\n",
    "            if save_float:\n",
    "                # For float conversion\n",
    "                window = [round(s[1], 2), round(s[2], 2)] # -> [start, end]\n",
    "                assert window[0] >= 0 and window[1] <= 1\n",
    "            else:\n",
    "                # For int conversion -> round to nearest int\n",
    "                window = [int(s[1] * 100), int(s[2] * 100)]\n",
    "                assert window[0] >= 0 and window[1] <= 100\n",
    "        else:\n",
    "            if save_float:\n",
    "                # For float conversion\n",
    "                window = [float(s[1]), float(s[2])] # -> [start, end]\n",
    "            else:\n",
    "                # For int conversion -> round to nearest int\n",
    "                window = [round(float(s[1])), round(float(s[2]))]\n",
    "\n",
    "        # get objects\n",
    "        objects = values[7]\n",
    "        # only split if objects is not nan or contains ; (which means multiple objects)\n",
    "        try:\n",
    "            objects = objects.split(';')\n",
    "        except:\n",
    "            print('no objects: ', objects, ' for id: ', id)\n",
    "            objects = []\n",
    "\n",
    "        out.append(\n",
    "            {\n",
    "                'id': id,\n",
    "                'query': query,\n",
    "                'window': [window],\n",
    "                'duration': duration,\n",
    "                'objects': objects\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = True\n",
    "relative_time = False\n",
    "\n",
    "train = process_charades_STA(train_path, train_df, train_ids, relative_time=relative_time, save_float=save_float)\n",
    "val = process_charades_STA(train_path, train_df, val_ids, save_float=save_float)\n",
    "test = process_charades_STA(test_path, test_df, save_float=save_float)\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978bc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72299f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For processing without the custom data slipt, i.e. having only the original train and test split\n",
    "\n",
    "save_float = True\n",
    "relative_time = False\n",
    "\n",
    "train = process_charades_STA(train_path, train_df, None, relative_time=relative_time, save_float=save_float)\n",
    "test = process_charades_STA(test_path, test_df, save_float=save_float)\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f67a5",
   "metadata": {},
   "source": [
    "# NextQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = 'Your/path/to/NExT_QA'\n",
    "raw_root = 'Your/path/to/raw/NExT'\n",
    "train_path = ann_root + '/nextqa/train.csv'\n",
    "val_path = ann_root + '/nextqa/val.csv'\n",
    "test_path = ann_root + '/nextqa/test.csv'\n",
    "map_vid_vidorID_path = ann_root + '/map_vid_vidorID.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv(train_path, delimiter=',')\n",
    "raw_val = pd.read_csv(val_path, delimiter=',')\n",
    "train = []\n",
    "val = []\n",
    "key = ['video', 'question', 'a0', 'a1', 'a2', 'a3', 'a4', 'answer', 'qid', 'type'] \n",
    "for i in range(len(raw_train)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_train.iloc[i][k]\n",
    "    train.append(data)\n",
    "\n",
    "for i in range(len(raw_val)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_val.iloc[i][k]\n",
    "    val.append(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8134eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_map = load_json(map_vid_vidorID_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63cf966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(vid):\n",
    "    vid_path = raw_root + \"/\" + vid_map[vid] + '.mp4'\n",
    "    clip = VideoFileClip(vid_path)\n",
    "    return clip.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1baa7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "\n",
    "print('Processing train and val data...')\n",
    "print('This could lake a while (100 min), because we need to extract the video durations for each video')\n",
    "\n",
    "for qa in train:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = vid_map[str(qa['video'])]\n",
    "    qa_dict['duration'] = get_video_duration(str(qa['video']))\n",
    "    qa_dict['num_option'] = int(5)\n",
    "    qa_dict['qid'] = '_'.join([qa['type'], str(qa['video']), str(qa['qid'])])\n",
    "    for i in range(5):\n",
    "        qa_dict['a{}'.format(str(i))] = qa['a{}'.format(str(i))]+'.'\n",
    "    qa_dict['answer'] = int(qa['answer'])\n",
    "    qa_dict['question'] = qa['question']+'?'\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for qa in val:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = vid_map[str(qa['video'])]\n",
    "    qa_dict['duration'] = get_video_duration(str(qa['video']))\n",
    "    qa_dict['num_option'] = int(5)\n",
    "    qa_dict['qid'] = '_'.join([qa['type'], str(qa['video']), str(qa['qid'])])\n",
    "    for i in range(5):\n",
    "        qa_dict['a{}'.format(str(i))] = qa['a{}'.format(str(i))]+'.'\n",
    "    qa_dict['answer'] = int(qa['answer'])\n",
    "    qa_dict['question'] = qa['question']+'?'\n",
    "    new_val.append(qa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51a2a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(new_train, ann_root + '/lavis/train.json')\n",
    "save_json(new_val, ann_root + '/lavis/val.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c30052",
   "metadata": {},
   "source": [
    "# NExT-GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = 'Your/path/to/NExT_QA'\n",
    "raw_root = 'Your/path/to/raw/NExT'\n",
    "# train_path = ann_root + '/nextgqa/train.csv'\n",
    "val_path = ann_root + '/nextgqa/val.csv'\n",
    "test_path = ann_root + '/nextgqa/test.csv'\n",
    "map_vid_vidorID_path = ann_root + '/map_vid_vidorID.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a239480",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val = pd.read_csv(val_path, delimiter=',')\n",
    "raw_test = pd.read_csv(test_path, delimiter=',')\n",
    "val = []\n",
    "test = []\n",
    "key = ['video_id', 'question', 'a0', 'a1', 'a2', 'a3', 'a4', 'answer', 'qid', 'type'] \n",
    "\n",
    "for i in range(len(raw_val)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_val.iloc[i][k]\n",
    "    val.append(data)\n",
    "\n",
    "for i in range(len(raw_test)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_test.iloc[i][k]\n",
    "    test.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22c038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_map = load_json(map_vid_vidorID_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebe3f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_val = load_json(ann_root + '/nextgqa/gsub_val.json')\n",
    "time_test = load_json(ann_root + '/nextgqa/gsub_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4a9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(vid):\n",
    "    vid_path = raw_root + \"/\" + vid_map[vid] + '.mp4'\n",
    "    clip = VideoFileClip(vid_path)\n",
    "    return clip.duration\n",
    "\n",
    "def get_answer_idx(answer, options):\n",
    "    for i, option in enumerate(options):\n",
    "        if option == answer:\n",
    "            return i\n",
    "    print('Error: answer not in options')\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a40d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moment_timespan(time_data, video_id, qid):\n",
    "    data = time_data[str(video_id)]\n",
    "    location = data['location'][str(qid)]\n",
    "    duration = data['duration']\n",
    "\n",
    "    return location, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5102bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val = []\n",
    "new_test = []\n",
    "\n",
    "# print('Processing train and val data...')\n",
    "# print('This could lake a while (100 min), because we need to extract the video durations for each video')\n",
    "\n",
    "for qa in val:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = vid_map[str(qa['video_id'])]\n",
    "    # qa_dict['duration'] = get_video_duration(str(qa['video_id']))\n",
    "    qa_dict['num_option'] = int(5)\n",
    "    qa_dict['qid'] = '_'.join([qa['type'], str(qa['video_id']), str(qa['qid'])])\n",
    "    for i in range(5):\n",
    "        qa_dict['a{}'.format(str(i))] = qa['a{}'.format(str(i))]+'.'\n",
    "    qa_dict['answer'] = get_answer_idx(qa['answer'], [qa['a0'], qa['a1'], qa['a2'], qa['a3'], qa['a4']])\n",
    "    qa_dict['question'] = qa['question']+'?'\n",
    "\n",
    "    ### GQA specific\n",
    "    relevant_windows, duration = get_moment_timespan(time_val, qa['video_id'], qa['qid'])\n",
    "    qa_dict['relevant_windows'] = relevant_windows\n",
    "    qa_dict['duration'] = duration\n",
    "\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for qa in test:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = vid_map[str(qa['video_id'])]\n",
    "    # qa_dict['duration'] = get_video_duration(str(qa['video_id']))\n",
    "    qa_dict['num_option'] = int(5)\n",
    "    qa_dict['qid'] = '_'.join([qa['type'], str(qa['video_id']), str(qa['qid'])])\n",
    "    for i in range(5):\n",
    "        qa_dict['a{}'.format(str(i))] = qa['a{}'.format(str(i))]+'.'\n",
    "    qa_dict['answer'] = get_answer_idx(qa['answer'], [qa['a0'], qa['a1'], qa['a2'], qa['a3'], qa['a4']])\n",
    "    qa_dict['question'] = qa['question']+'?'\n",
    "\n",
    "    ### GQA specific\n",
    "    relevant_windows, duration = get_moment_timespan(time_test, qa['video_id'], qa['qid'])\n",
    "    qa_dict['relevant_windows'] = relevant_windows\n",
    "    qa_dict['duration'] = duration\n",
    "\n",
    "    new_test.append(qa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627659e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(new_val, ann_root + '/lavis/nextgqa/val.json')\n",
    "save_json(new_test, ann_root + '/lavis/nextgqa/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b041cad",
   "metadata": {},
   "source": [
    "# ActivityNet Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43920332",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"Your/path/to/ActivityNet\"\n",
    "train_path = os.path.join(ann_root, \"train.json\")\n",
    "val_path = os.path.join(ann_root, \"val_1.json\")\n",
    "test_path = os.path.join(ann_root, \"val_2.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_json(train_path)\n",
    "val = load_json(val_path)\n",
    "test = load_json(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee346274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_activitynet(data, relative_time=False, save_float=False):\n",
    "    out = []\n",
    "\n",
    "    for video_id, sample in data.items():\n",
    "        duration = sample['duration']\n",
    "        sentences = sample['sentences']\n",
    "        timestamps = sample['timestamps']\n",
    "        for j, (start, end) in enumerate(timestamps):\n",
    "\n",
    "            if relative_time:\n",
    "                # convert to relative time\n",
    "                start = start / duration\n",
    "                end = end / duration\n",
    "\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [round(start, 2), round(end, 2)]\n",
    "                    assert window[0] >= 0 and window[1] <= 1\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [int(round(start, 2) * 100), int(round(end, 2) * 100)]\n",
    "                    assert window[0] >= 0 and window[1] <= 100\n",
    "            else:\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [float(start), float(end)]\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [round(float(start)), round(float(end))]\n",
    "\n",
    "            new_sample = {\n",
    "                'video': video_id,\n",
    "                'qid': f'ActivityNet_{video_id}_{j}',\n",
    "                'query': sentences[j],\n",
    "                'duration': duration,\n",
    "                'relevant_windows': [window]\n",
    "            }\n",
    "\n",
    "            out.append(new_sample)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "new_train = process_activitynet(train, relative_time=relative_time, save_float=save_float)\n",
    "new_val = process_activitynet(val, save_float=save_float)\n",
    "new_test = process_activitynet(test, save_float=save_float)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
