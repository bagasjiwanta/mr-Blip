{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4204c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/determined/pythonuserbase/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "import random\n",
    "# from tqdm import tqdm\n",
    "# tqdm for notebooks\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e807f09",
   "metadata": {},
   "source": [
    "# create folder for each dataset first    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09845339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(content, save_path):\n",
    "    # if no such directory, create one\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(json.dumps(content))\n",
    "def load_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [json.loads(l.strip(\"\\n\")) for l in f.readlines()]\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7083bf5",
   "metadata": {},
   "source": [
    "# qvh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a00480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/QVHighlights'\n",
    "# ann_root = \"../../data/annotations\"\n",
    "train_path = ann_root + '/highlight_train_release.jsonl'\n",
    "val_path = ann_root + '/highlight_val_release.jsonl'\n",
    "test_path = ann_root + '/highlight_test_release.jsonl'\n",
    "\n",
    "train_mcq_path = ann_root + '/Meta-Llama-3.1-70B-Instruct_qv_highlights_multiple_choice_qa.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc2f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)\n",
    "test = load_jsonl(test_path)\n",
    "\n",
    "train_mcq = load_json(train_mcq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d681ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_QVH(data, relative_time=False, save_float=False, is_test=False):\n",
    "    out = []\n",
    "    for d in data:\n",
    "        sample = {}\n",
    "        sample['video'] = d['vid']\n",
    "        sample['qid'] = 'QVHighlight_' + str(d['qid'])\n",
    "        sample['query'] = d['query']\n",
    "        duration = d['duration']\n",
    "        sample['duration'] = duration\n",
    "\n",
    "        if not is_test:\n",
    "            windows = d['relevant_windows']\n",
    "            if relative_time:\n",
    "                relative_time_windows = []\n",
    "                for window in windows:\n",
    "                    start = window[0] / duration\n",
    "                    end = window[1] / duration\n",
    "\n",
    "                    if save_float:\n",
    "                        relative_time_windows.append([round(start, 2), round(end, 2)])\n",
    "                    else:\n",
    "                        relative_time_windows.append([int(round(start, 2) * 100), int(round(end, 2) * 100)])\n",
    "                sample['relevant_windows'] = relative_time_windows\n",
    "            else:\n",
    "                sample['relevant_windows'] = windows\n",
    "        else:\n",
    "            sample['relevant_windows'] = [[0, 150]] # dummy value\n",
    "\n",
    "        out.append(sample)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507365fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "new_train = process_QVH(train, relative_time=relative_time, save_float=save_float)\n",
    "new_val = process_QVH(val, relative_time=relative_time, save_float=save_float)\n",
    "new_test = process_QVH(test, relative_time=relative_time, save_float=save_float, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9754fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float_dummy.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float_dummy.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_dummy.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_dummy.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7aae719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process QVH_QA\n",
    "\n",
    "errors_no_similar_answer = []\n",
    "\n",
    "def process_QVH_QA(data_mc, data_og, relative_time=False, save_float=False):\n",
    "    out = []\n",
    "    for d in data_og:\n",
    "        sample = {}\n",
    "        sample['video'] = d['vid']\n",
    "        sample['qid'] = 'QVHighlight_' + str(d['qid'])\n",
    "        duration = d['duration']\n",
    "        sample['duration'] = duration\n",
    "        windows = d['relevant_windows']\n",
    "\n",
    "        # get data from multiple choice\n",
    "        if str(d['qid']) in data_mc:\n",
    "            d_q = data_mc[str(d['qid'])]\n",
    "        else:\n",
    "            # print('Error: qid {} not in data_mc'.format(d['qid']))\n",
    "            continue\n",
    "\n",
    "        sample['query'] = d_q['question']\n",
    "        sample['question'] = d_q['question']\n",
    "        sample['answer_str'] = d_q['answer']\n",
    "        options = d_q['choices']\n",
    "        # split options by comma\n",
    "        options = options.split(',')\n",
    "        # remove leading and trailing whitespaces\n",
    "        options = [x.strip() for x in options]\n",
    "        \n",
    "        sample['num_option'] = len(options)\n",
    "        \n",
    "        for i, option in enumerate(options):\n",
    "            sample[f\"a{i}\"] = option\n",
    "\n",
    "        # get correct answer index\n",
    "        try:\n",
    "            correct_idx = options.index(d_q['answer'])\n",
    "        except:\n",
    "            # if the correct answer does not 100% match any of the options, look for the most similar one\n",
    "            closest_answer = None\n",
    "            closest_score = 0\n",
    "            for i, option in enumerate(options):\n",
    "                score = fuzz.ratio(d_q['answer'], option)\n",
    "                if score > closest_score:\n",
    "                    closest_score = score\n",
    "                    closest_answer = i\n",
    "            \n",
    "            errors_no_similar_answer.append(d['qid'])\n",
    "            if closest_score > 40:\n",
    "                correct_idx = closest_answer\n",
    "            else:\n",
    "                print('Error: no similar answer found')\n",
    "                print('Error: >{}< not in {}'.format(d_q['answer'], options))\n",
    "                continue\n",
    "\n",
    "        sample['answer'] = correct_idx\n",
    "\n",
    "        if relative_time:\n",
    "            relative_time_windows = []\n",
    "            for window in windows:\n",
    "                start = window[0] / duration\n",
    "                end = window[1] / duration\n",
    "\n",
    "                if save_float:\n",
    "                    relative_time_windows.append([round(start, 2), round(end, 2)])\n",
    "                else:\n",
    "                    relative_time_windows.append([int(round(start, 2) * 100), int(round(end, 2) * 100)])\n",
    "            sample['relevant_windows'] = relative_time_windows\n",
    "        else:\n",
    "            sample['relevant_windows'] = windows\n",
    "\n",
    "        out.append(sample)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab5eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "new_train_mc = process_QVH_QA(train_mcq, train, relative_time=relative_time, save_float=save_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57b70e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if not save_float and not relative_time:\n",
    "    save_json(new_train_mc, ann_root + '/lavis/train_mcqa.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151075f",
   "metadata": {},
   "source": [
    "# Charades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv from /pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/Charades/Charades_v1_train.csv\n",
    "train_df = pd.read_csv('/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/Charades/Charades_original/Charades_v1_train.csv', delimiter=',')\n",
    "test_df = pd.read_csv('/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/Charades/Charades_original/Charades_v1_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique ids\n",
    "train_ids = train_df[\"id\"].unique()\n",
    "print(len(train_ids))\n",
    "\n",
    "# randomly select 800 ids for validation\n",
    "random.seed(42)\n",
    "random.shuffle(train_ids)\n",
    "\n",
    "val_ids = train_ids[:800]\n",
    "train_ids = train_ids[800:]\n",
    "\n",
    "len(val_ids), len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/Charades/Charades_STA'\n",
    "train_path = ann_root + '/train.txt'\n",
    "test_path = ann_root + '/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_charades_STA(data_path, df, video_ids=None, relative_time=False, save_float=False):\n",
    "    # read txt and put each line into new element in list\n",
    "    with open(data_path) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    out = []\n",
    "\n",
    "    for s in content:\n",
    "        # format \"id start end##query\"\n",
    "        s = s.split('##') # -> [id start end, query]\n",
    "        query = s[1] # -> query\n",
    "        s = s[0] # -> id start end\n",
    "        s = s.split(' ') # -> [[id], [start], [end]]\n",
    "        id = s[0] # -> id\n",
    "\n",
    "        if video_ids is not None and id not in video_ids:\n",
    "            continue\n",
    "        \n",
    "        # get meta data from df using id\n",
    "        # get row with id == id\n",
    "        row = df.loc[df[\"id\"] == id]\n",
    "        values = row.values[0]\n",
    "\n",
    "        # get duration\n",
    "        duration = values[10]\n",
    "\n",
    "        # convert to float\n",
    "        s[1] = float(s[1])\n",
    "        s[2] = float(s[2])\n",
    "        if s[2] > duration:\n",
    "            s[2] = duration\n",
    "\n",
    "        if relative_time:\n",
    "            # convert to relative time\n",
    "            s[1] = s[1] / duration\n",
    "            s[2] = s[2] / duration\n",
    "\n",
    "            if save_float:\n",
    "                # For float conversion\n",
    "                window = [round(s[1], 2), round(s[2], 2)] # -> [start, end]\n",
    "                assert window[0] >= 0 and window[1] <= 1\n",
    "            else:\n",
    "                # For int conversion -> round to nearest int\n",
    "                window = [int(s[1] * 100), int(s[2] * 100)]\n",
    "                assert window[0] >= 0 and window[1] <= 100\n",
    "        else:\n",
    "            if save_float:\n",
    "                # For float conversion\n",
    "                window = [float(s[1]), float(s[2])] # -> [start, end]\n",
    "            else:\n",
    "                # For int conversion -> round to nearest int\n",
    "                window = [round(float(s[1])), round(float(s[2]))]\n",
    "\n",
    "        # get objects\n",
    "        objects = values[7]\n",
    "        # only split if objects is not nan or contains ; (which means multiple objects)\n",
    "        try:\n",
    "            objects = objects.split(';')\n",
    "        except:\n",
    "            print('no objects: ', objects, ' for id: ', id)\n",
    "            objects = []\n",
    "\n",
    "        out.append(\n",
    "            {\n",
    "                'id': id,\n",
    "                'query': query,\n",
    "                'window': [window],\n",
    "                'duration': duration,\n",
    "                'objects': objects\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = True\n",
    "relative_time = False\n",
    "\n",
    "train = process_charades_STA(train_path, train_df, train_ids, relative_time=relative_time, save_float=save_float)\n",
    "val = process_charades_STA(train_path, train_df, val_ids, save_float=save_float)\n",
    "test = process_charades_STA(test_path, test_df, save_float=save_float)\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978bc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72299f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For processing without the custom data slipt, i.e. having only the original train and test split\n",
    "\n",
    "save_float = True\n",
    "relative_time = False\n",
    "\n",
    "train = process_charades_STA(train_path, train_df, None, relative_time=relative_time, save_float=save_float)\n",
    "test = process_charades_STA(test_path, test_df, save_float=save_float)\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f67a5",
   "metadata": {},
   "source": [
    "# NextQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6187e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/NExT_QA'\n",
    "raw_root = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/raw/NExT'\n",
    "train_path = ann_root + '/nextqa/train.csv'\n",
    "val_path = ann_root + '/nextqa/val.csv'\n",
    "test_path = ann_root + '/nextqa/test.csv'\n",
    "map_vid_vidorID_path = ann_root + '/map_vid_vidorID.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv(train_path, delimiter=',')\n",
    "raw_val = pd.read_csv(val_path, delimiter=',')\n",
    "train = []\n",
    "val = []\n",
    "key = ['video', 'question', 'a0', 'a1', 'a2', 'a3', 'a4', 'answer', 'qid', 'type'] \n",
    "for i in range(len(raw_train)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_train.iloc[i][k]\n",
    "    train.append(data)\n",
    "\n",
    "for i in range(len(raw_val)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_val.iloc[i][k]\n",
    "    val.append(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8134eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_map = load_json(map_vid_vidorID_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63cf966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(vid):\n",
    "    vid_path = raw_root + \"/\" + vid_map[vid] + '.mp4'\n",
    "    clip = VideoFileClip(vid_path)\n",
    "    return clip.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1baa7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "\n",
    "print('Processing train and val data...')\n",
    "print('This could lake a while (100 min), because we need to extract the video durations for each video')\n",
    "\n",
    "for qa in train:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = vid_map[str(qa['video'])]\n",
    "    qa_dict['duration'] = get_video_duration(str(qa['video']))\n",
    "    qa_dict['num_option'] = int(5)\n",
    "    qa_dict['qid'] = '_'.join([qa['type'], str(qa['video']), str(qa['qid'])])\n",
    "    for i in range(5):\n",
    "        qa_dict['a{}'.format(str(i))] = qa['a{}'.format(str(i))]+'.'\n",
    "    qa_dict['answer'] = int(qa['answer'])\n",
    "    qa_dict['question'] = qa['question']+'?'\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for qa in val:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = vid_map[str(qa['video'])]\n",
    "    qa_dict['duration'] = get_video_duration(str(qa['video']))\n",
    "    qa_dict['num_option'] = int(5)\n",
    "    qa_dict['qid'] = '_'.join([qa['type'], str(qa['video']), str(qa['qid'])])\n",
    "    for i in range(5):\n",
    "        qa_dict['a{}'.format(str(i))] = qa['a{}'.format(str(i))]+'.'\n",
    "    qa_dict['answer'] = int(qa['answer'])\n",
    "    qa_dict['question'] = qa['question']+'?'\n",
    "    new_val.append(qa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51a2a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(new_train, ann_root + '/lavis/train.json')\n",
    "save_json(new_val, ann_root + '/lavis/val.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c30052",
   "metadata": {},
   "source": [
    "# NExT-GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5e53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/NExT_QA'\n",
    "raw_root = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/raw/NExT'\n",
    "# train_path = ann_root + '/nextgqa/train.csv'\n",
    "val_path = ann_root + '/nextgqa/val.csv'\n",
    "test_path = ann_root + '/nextgqa/test.csv'\n",
    "map_vid_vidorID_path = ann_root + '/map_vid_vidorID.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a239480",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val = pd.read_csv(val_path, delimiter=',')\n",
    "raw_test = pd.read_csv(test_path, delimiter=',')\n",
    "val = []\n",
    "test = []\n",
    "key = ['video_id', 'question', 'a0', 'a1', 'a2', 'a3', 'a4', 'answer', 'qid', 'type'] \n",
    "\n",
    "for i in range(len(raw_val)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_val.iloc[i][k]\n",
    "    val.append(data)\n",
    "\n",
    "for i in range(len(raw_test)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_test.iloc[i][k]\n",
    "    test.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22c038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_map = load_json(map_vid_vidorID_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebe3f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_val = load_json(ann_root + '/nextgqa/gsub_val.json')\n",
    "time_test = load_json(ann_root + '/nextgqa/gsub_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4a9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(vid):\n",
    "    vid_path = raw_root + \"/\" + vid_map[vid] + '.mp4'\n",
    "    clip = VideoFileClip(vid_path)\n",
    "    return clip.duration\n",
    "\n",
    "def get_answer_idx(answer, options):\n",
    "    for i, option in enumerate(options):\n",
    "        if option == answer:\n",
    "            return i\n",
    "    print('Error: answer not in options')\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a40d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moment_timespan(time_data, video_id, qid):\n",
    "    data = time_data[str(video_id)]\n",
    "    location = data['location'][str(qid)]\n",
    "    duration = data['duration']\n",
    "\n",
    "    return location, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5102bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val = []\n",
    "new_test = []\n",
    "\n",
    "# print('Processing train and val data...')\n",
    "# print('This could lake a while (100 min), because we need to extract the video durations for each video')\n",
    "\n",
    "for qa in val:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = vid_map[str(qa['video_id'])]\n",
    "    # qa_dict['duration'] = get_video_duration(str(qa['video_id']))\n",
    "    qa_dict['num_option'] = int(5)\n",
    "    qa_dict['qid'] = '_'.join([qa['type'], str(qa['video_id']), str(qa['qid'])])\n",
    "    for i in range(5):\n",
    "        qa_dict['a{}'.format(str(i))] = qa['a{}'.format(str(i))]+'.'\n",
    "    qa_dict['answer'] = get_answer_idx(qa['answer'], [qa['a0'], qa['a1'], qa['a2'], qa['a3'], qa['a4']])\n",
    "    qa_dict['question'] = qa['question']+'?'\n",
    "\n",
    "    ### GQA specific\n",
    "    relevant_windows, duration = get_moment_timespan(time_val, qa['video_id'], qa['qid'])\n",
    "    qa_dict['relevant_windows'] = relevant_windows\n",
    "    qa_dict['duration'] = duration\n",
    "\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for qa in test:\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = vid_map[str(qa['video_id'])]\n",
    "    # qa_dict['duration'] = get_video_duration(str(qa['video_id']))\n",
    "    qa_dict['num_option'] = int(5)\n",
    "    qa_dict['qid'] = '_'.join([qa['type'], str(qa['video_id']), str(qa['qid'])])\n",
    "    for i in range(5):\n",
    "        qa_dict['a{}'.format(str(i))] = qa['a{}'.format(str(i))]+'.'\n",
    "    qa_dict['answer'] = get_answer_idx(qa['answer'], [qa['a0'], qa['a1'], qa['a2'], qa['a3'], qa['a4']])\n",
    "    qa_dict['question'] = qa['question']+'?'\n",
    "\n",
    "    ### GQA specific\n",
    "    relevant_windows, duration = get_moment_timespan(time_test, qa['video_id'], qa['qid'])\n",
    "    qa_dict['relevant_windows'] = relevant_windows\n",
    "    qa_dict['duration'] = duration\n",
    "\n",
    "    new_test.append(qa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627659e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(new_val, ann_root + '/lavis/nextgqa/val.json')\n",
    "save_json(new_test, ann_root + '/lavis/nextgqa/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7796993",
   "metadata": {},
   "source": [
    "# Epic Sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011173c8",
   "metadata": {},
   "source": [
    "Do the same as above for the other datasets but now also ectract save the audio files (.wav) for the relevant moments in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030e17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_annotations = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/EpicSounds/epic-sounds-annotations'\n",
    "train_path = path_to_annotations + '/EPIC_Sounds_train.csv'\n",
    "val_path = path_to_annotations + '/EPIC_Sounds_validation.csv'\n",
    "test_path = path_to_annotations + '/EPIC_Sounds_recognition_test_timestamps.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path, delimiter=',')\n",
    "val_df = pd.read_csv(val_path, delimiter=',')\n",
    "test_df = pd.read_csv(test_path, delimiter=',')\n",
    "\n",
    "path_to_raw = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/raw/EPIC-KITCHENS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1048ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_segment(video, output_path, start_time, end_time):\n",
    "    if start_time > end_time:\n",
    "        print('Start time is greater than end time')\n",
    "        return\n",
    "\n",
    "    def safe_subclip(video, start, end):\n",
    "        return video.audio.subclip(start, min(end, video.duration))\n",
    "\n",
    "    # Extract the audio from the specified time range\n",
    "    # audio_clip = video.audio.subclip(start_time, end_time, verbose=False)\n",
    "    audio_clip = safe_subclip(video, start_time, end_time)\n",
    "    \n",
    "    # Write the audio to a file\n",
    "    # if file does not already exist\n",
    "    # if not os.path.exists(output_path):\n",
    "    audio_clip.write_audiofile(output_path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89ad209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_seconds(timestamp):\n",
    "    parts = timestamp.split(':')\n",
    "    \n",
    "    if len(parts) == 3:  # Format: HH:MM:SS.mmm\n",
    "        hours, minutes, seconds = parts\n",
    "    elif len(parts) == 2:  # Format: MM:SS.mmm\n",
    "        hours = '0'\n",
    "        minutes, seconds = parts\n",
    "    else:\n",
    "        raise ValueError(\"Invalid timestamp format\")\n",
    "    \n",
    "    seconds, milliseconds = seconds.split('.')\n",
    "    \n",
    "    total_seconds = (\n",
    "        int(hours) * 3600 +\n",
    "        int(minutes) * 60 +\n",
    "        int(seconds) +\n",
    "        int(milliseconds) / 1000\n",
    "    )\n",
    "    \n",
    "    return total_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e75f7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proccess_EPIC_Sounds(df, split=\"train\" ,relative_time=False, save_float=False):\n",
    "    assert split in [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    out = []\n",
    "\n",
    "    video_cache = {}\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        sample = {}\n",
    "        sample['video'] = row['video_id']\n",
    "        sample['qid'] = 'EPIC-Sounds_' + str(row['annotation_id'])\n",
    "\n",
    "        video_path = os.path.join(path_to_raw, row['participant_id'], \"videos\", row['video_id'] + '.MP4')\n",
    "\n",
    "        ### get the video and its duration if not already in cache #############################################\n",
    "        if row['video_id'] not in video_cache:\n",
    "            if len(video_cache) > 10:\n",
    "                print(\"Freeing up cache:\", video_cache.keys())\n",
    "                for video in video_cache.values():\n",
    "                    video['VideoFileClip'].close()\n",
    "                video_cache = {}\n",
    "\n",
    "            print(f'loading video: {video_path}')\n",
    "            video = VideoFileClip(video_path, verbose=False)\n",
    "            print(f'duration: {video.duration}')\n",
    "            video_cache[row['video_id']] = {'VideoFileClip': video, 'duration': video.duration}\n",
    "        \n",
    "        sample['duration'] = video_cache[row['video_id']]['duration']\n",
    "\n",
    "        ########################################################################################################\n",
    "\n",
    "        ### get audio sequence from video given start and end time for audio ###################################\n",
    "        audio_path = os.path.join(path_to_raw, 'EpicSounds', split, str(row['annotation_id']) + '.wav')\n",
    "        start = row['start_timestamp']\n",
    "        end = row['stop_timestamp']\n",
    "        # convert time format (00:00:02.466 or 01:56.091) to float\n",
    "        start = timestamp_to_seconds(start)\n",
    "        end = timestamp_to_seconds(end)\n",
    "        \n",
    "        # extract audio\n",
    "        extract_audio_segment(video_cache[row['video_id']]['VideoFileClip'], audio_path, start, end)\n",
    "        \n",
    "        sample['query'] = audio_path\n",
    "        ########################################################################################################\n",
    "\n",
    "        # if the class key exists\n",
    "        if 'class' in row:\n",
    "            sample['class'] = row['class']\n",
    "\n",
    "        if relative_time:\n",
    "            if save_float:\n",
    "                sample['relevant_windows'] = [[round(start, 2), round(end, 2)]]\n",
    "            else:\n",
    "                sample['relevant_windows'] = [[int(round(start, 2) * 100), int(round(end, 2) * 100)]]\n",
    "        else:\n",
    "            if save_float:\n",
    "                sample['relevant_windows'] = [[round(start, 2), round(end, 2)]]\n",
    "            else:\n",
    "                sample['relevant_windows'] = [[round(start), round(end)]]\n",
    "\n",
    "        out.append(sample)\n",
    "    \n",
    "    # clear cache\n",
    "    for video in video_cache.values():\n",
    "        video['VideoFileClip'].close()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = True\n",
    "relative_time = False\n",
    "\n",
    "# new_train = proccess_EPIC_Sounds(train_df, split=\"train\", relative_time=relative_time, save_float=save_float)\n",
    "new_val = proccess_EPIC_Sounds(val_df, split=\"val\", save_float=True)\n",
    "# new_test = proccess_EPIC_Sounds(test_df, split=\"test\", save_float=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177748ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b225d55",
   "metadata": {},
   "source": [
    "# TACoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "# import VideoFileClip\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808905a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/raw/\"\n",
    "directory_avi = os.path.join(base_path, \"videos\")\n",
    "directory_mp4 = os.path.join(base_path, \"TACoS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ef371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert avi to mp4 \n",
    "\n",
    "def convert_avi_to_mp4(filename, avi_path, target_path):\n",
    "    os.system('ffmpeg -i {} {}'.format(\n",
    "        os.path.join(avi_path, filename),\n",
    "        os.path.join(target_path, filename.replace('.avi', '.mp4'))\n",
    "    ))\n",
    "\n",
    "# get all avi files\n",
    "avi_files = glob(os.path.join(directory_avi, \"*.avi\"))\n",
    "avi_files = [os.path.basename(f) for f in avi_files]\n",
    "\n",
    "# convert all avi files to mp4\n",
    "for avi_file in avi_files:\n",
    "    # if file already exists, skip\n",
    "    if not os.path.exists(os.path.join(directory_mp4, avi_file.replace('.avi', '.mp4'))):\n",
    "        convert_avi_to_mp4(avi_file, directory_avi, directory_mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a987d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downscale resolution to 224x224\n",
    "target_path = os.path.join(directory_mp4, \"res_224\")\n",
    "\n",
    "def downscale_resolution(filename, source_path, target_path):\n",
    "    os.system('ffmpeg -i {} -vf scale=224:224 {}'.format(\n",
    "        os.path.join(source_path, filename),\n",
    "        os.path.join(target_path, filename)\n",
    "    ))\n",
    "\n",
    "# get all mp4 files\n",
    "mp4_files = glob(os.path.join(directory_mp4, \"*.mp4\"))\n",
    "mp4_files = [os.path.basename(f) for f in mp4_files]\n",
    "\n",
    "# downscale all mp4 files to 224x224\n",
    "for mp4_file in mp4_files:\n",
    "    # if file already exists, skip\n",
    "    if not os.path.exists(os.path.join(target_path, mp4_file)):\n",
    "        downscale_resolution(mp4_file, directory_mp4, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/TACoS\"\n",
    "train_path = os.path.join(ann_root, \"train.jsonl\")\n",
    "val_path = os.path.join(ann_root, \"val.jsonl\")\n",
    "test_path = os.path.join(ann_root, \"test.jsonl\")\n",
    "\n",
    "\n",
    "video_path = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/raw/TACoS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53724b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read jsonl\n",
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)\n",
    "test = load_jsonl(test_path)\n",
    "\n",
    "# show length of each split\n",
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20796021",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = True\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid']\n",
    "    qa_dict['qid'] = 'TACoS_' + str(qa['qid'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    # round duration to 2 decimal places\n",
    "    qa_dict['duration'] = round(qa['duration'], 2)\n",
    "    \n",
    "    assert len(qa['relevant_windows']) == 1\n",
    "\n",
    "    start, end = qa['relevant_windows'][0]\n",
    "    if relative_time:\n",
    "        # convert to relative time\n",
    "        start = start / qa['duration']\n",
    "        end = end / qa['duration']\n",
    "\n",
    "        if save_float:\n",
    "            # For float conversion\n",
    "            window = [round(start, 2), round(end, 2)] # -> [start, end]\n",
    "            assert window[0] >= 0 and window[1] <= 1\n",
    "            qa_dict['relevant_windows'] = [window]\n",
    "        else:\n",
    "            # For int conversion -> round to nearest int\n",
    "            window = [int(round(start, 2) * 100), int(round(end, 2) * 100)]\n",
    "            assert window[0] >= 0 and window[1] <= 100\n",
    "            qa_dict['relevant_windows'] = [window]\n",
    "    else:\n",
    "        if save_float:\n",
    "            # For float conversion\n",
    "            window = [float(start), float(end)] # -> [start, end]\n",
    "            qa_dict['relevant_windows'] = [window]\n",
    "        else:\n",
    "            # For int conversion -> round to nearest int\n",
    "            window = [round(float(start)), round(float(end))]\n",
    "            qa_dict['relevant_windows'] = [window]\n",
    "    \n",
    "    # qa_dict['objects'] = qa['objects']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid']\n",
    "    qa_dict['qid'] = 'TACoS_' + str(qa['qid'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    # round duration to 2 decimal places\n",
    "    qa_dict['duration'] = round(qa['duration'], 2)\n",
    "    \n",
    "    # round relevant windows to 2 decimal places\n",
    "    assert len(qa['relevant_windows']) == 1\n",
    "    if save_float:\n",
    "        qa_dict['relevant_windows'] = [[float(round(x, 2)) for x in qa['relevant_windows'][0]]]\n",
    "    else:\n",
    "        qa_dict['relevant_windows'] = [[int(round(x)) for x in qa['relevant_windows'][0]]]\n",
    "    \n",
    "    \n",
    "    # qa_dict['objects'] = qa['objects']\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid']\n",
    "    qa_dict['qid'] = 'TACoS_' + str(qa['qid'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    # round duration to 2 decimal places\n",
    "    qa_dict['duration'] = round(qa['duration'], 2)\n",
    "    \n",
    "    # round relevant windows to 2 decimal places\n",
    "    assert len(qa['relevant_windows']) == 1\n",
    "    if save_float:\n",
    "        qa_dict['relevant_windows'] = [[float(round(x, 2)) for x in qa['relevant_windows'][0]]]\n",
    "    else:\n",
    "        qa_dict['relevant_windows'] = [[int(round(x)) for x in qa['relevant_windows'][0]]]\n",
    "    \n",
    "    # qa_dict['objects'] = qa['objects']\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddbe175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b041cad",
   "metadata": {},
   "source": [
    "# ActivityNet Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43920332",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/ActivityNet\"\n",
    "train_path = os.path.join(ann_root, \"train.json\")\n",
    "val_path = os.path.join(ann_root, \"val_1.json\")\n",
    "test_path = os.path.join(ann_root, \"val_2.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_json(train_path)\n",
    "val = load_json(val_path)\n",
    "test = load_json(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee346274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_activitynet(data, relative_time=False, save_float=False):\n",
    "    out = []\n",
    "\n",
    "    for video_id, sample in data.items():\n",
    "        duration = sample['duration']\n",
    "        sentences = sample['sentences']\n",
    "        timestamps = sample['timestamps']\n",
    "        for j, (start, end) in enumerate(timestamps):\n",
    "\n",
    "            if relative_time:\n",
    "                # convert to relative time\n",
    "                start = start / duration\n",
    "                end = end / duration\n",
    "\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [round(start, 2), round(end, 2)]\n",
    "                    assert window[0] >= 0 and window[1] <= 1\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [int(round(start, 2) * 100), int(round(end, 2) * 100)]\n",
    "                    assert window[0] >= 0 and window[1] <= 100\n",
    "            else:\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [float(start), float(end)]\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [round(float(start)), round(float(end))]\n",
    "\n",
    "            new_sample = {\n",
    "                'video': video_id,\n",
    "                'qid': f'ActivityNet_{video_id}_{j}',\n",
    "                'query': sentences[j],\n",
    "                'duration': duration,\n",
    "                'relevant_windows': [window]\n",
    "            }\n",
    "\n",
    "            out.append(new_sample)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "new_train = process_activitynet(train, relative_time=relative_time, save_float=save_float)\n",
    "new_val = process_activitynet(val, save_float=save_float)\n",
    "new_test = process_activitynet(test, save_float=save_float)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e7648",
   "metadata": {},
   "source": [
    "# ANet TAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832227fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/ActivityNet_TAL\"\n",
    "data = load_json(ann_root + '/anet_tal.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_all = [\n",
    "    'a photo of {}.',\n",
    "    'a photo of a person {}.',\n",
    "    'a photo of a person using {}.',\n",
    "    'a photo of a person doing {}.',\n",
    "    'a photo of a person during {}.',\n",
    "    'a photo of a person performing {}.',\n",
    "    'a photo of a person practicing {}.',\n",
    "    'a video of {}.',\n",
    "    'a video of a person {}.',\n",
    "    'a video of a person using {}.',\n",
    "    'a video of a person doing {}.',\n",
    "    'a video of a person during {}.',\n",
    "    'a video of a person performing {}.',\n",
    "    'a video of a person practicing {}.',\n",
    "    'a example of {}.',\n",
    "    'a example of a person {}.',\n",
    "    'a example of a person using {}.',\n",
    "    'a example of a person doing {}.',\n",
    "    'a example of a person during {}.',\n",
    "    'a example of a person performing {}.',\n",
    "    'a example of a person practicing {}.',\n",
    "    'a demonstration of {}.',\n",
    "    'a demonstration of a person {}.',\n",
    "    'a demonstration of a person using {}.',\n",
    "    'a demonstration of a person doing {}.',\n",
    "    'a demonstration of a person during {}.',\n",
    "    'a demonstration of a person performing {}.',\n",
    "    'a demonstration of a person practicing {}.',\n",
    "]\n",
    "\n",
    "templates_video = [\n",
    "    'a video of {}.',\n",
    "    'a video of a person {}.',\n",
    "    'a video of a person using {}.',\n",
    "    'a video of a person doing {}.',\n",
    "    'a video of a person during {}.',\n",
    "    'a video of a person performing {}.',\n",
    "    'a video of a person practicing {}.',\n",
    "    'a example of {}.',\n",
    "    'a example of a person {}.',\n",
    "    'a example of a person using {}.',\n",
    "    'a example of a person doing {}.',\n",
    "    'a example of a person during {}.',\n",
    "    'a example of a person performing {}.',\n",
    "    'a example of a person practicing {}.',\n",
    "    'a demonstration of {}.',\n",
    "    'a demonstration of a person {}.',\n",
    "    'a demonstration of a person using {}.',\n",
    "    'a demonstration of a person doing {}.',\n",
    "    'a demonstration of a person during {}.',\n",
    "    'a demonstration of a person performing {}.',\n",
    "    'a demonstration of a person practicing {}.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82913c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_activitynet_tal(data, relative_time=False, save_float=False):\n",
    "    out_train = []\n",
    "    out_val = []\n",
    "    out_test = []\n",
    "\n",
    "    for video_id, sample in data.items():\n",
    "        video_id = \"v_\" + video_id\n",
    "        duration = sample['duration']\n",
    "        split = sample['subset']\n",
    "        annotations = sample['annotations']\n",
    "        windows = []\n",
    "        for ann in annotations:\n",
    "            start = ann['segment'][0]\n",
    "            end = ann['segment'][1]\n",
    "\n",
    "            # label will always be the same for all annotations/ windows\n",
    "            label = ann['label']\n",
    "\n",
    "            if relative_time:\n",
    "                # convert to relative time\n",
    "                start = start / duration\n",
    "                end = end / duration\n",
    "\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [round(start, 2), round(end, 2)]\n",
    "                    assert window[0] >= 0 and window[1] <= 1\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [int(round(start, 2) * 100), int(round(end, 2) * 100)]\n",
    "                    assert window[0] >= 0 and window[1] <= 100\n",
    "            else:\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [float(start), float(end)]\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [round(float(start)), round(float(end))]\n",
    "            \n",
    "            window.extend([label])\n",
    "\n",
    "            windows.append(window)\n",
    "\n",
    "        # get one example of the template and insert the label in lower case\n",
    "        # query = random.choice(templates_video).format(label.lower())\n",
    "        query = \"\"\n",
    "\n",
    "        new_sample = {\n",
    "            'video': video_id,\n",
    "            'qid': f'ActivityNet_{video_id}_0',\n",
    "            'query': query,\n",
    "            'duration': duration,\n",
    "            'relevant_windows': windows\n",
    "        }\n",
    "\n",
    "        if split == 'training':\n",
    "            out_train.append(new_sample)\n",
    "        elif split == 'validation':\n",
    "            out_val.append(new_sample)\n",
    "        elif split == 'testing':\n",
    "            out_test.append(new_sample)\n",
    "    \n",
    "    return out_train, out_val, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "train, val, test = process_activitynet_tal(data[\"database\"], relative_time=relative_time, save_float=save_float)\n",
    "\n",
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f110155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(train, ann_root + '/lavis/train.json')\n",
    "    save_json(val, ann_root + '/lavis/val.json')\n",
    "    save_json(test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique classes from activitynet\n",
    "classes = []\n",
    "for video_id, sample in data[\"database\"].items():\n",
    "    annotations = sample['annotations']\n",
    "    for ann in annotations:\n",
    "        label = ann['label']\n",
    "        if label not in classes:\n",
    "            classes.append(label)\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f179781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to txt file\n",
    "with open('classes.txt', 'w') as f:\n",
    "    for item in classes:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
